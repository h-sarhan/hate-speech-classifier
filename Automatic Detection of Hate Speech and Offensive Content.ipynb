{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1698331d",
   "metadata": {},
   "source": [
    "# Automatic Detection of Hate Speech and Offensive Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "396c13c8-0060-46dc-84d4-cfa5bb67420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert html character entities to unicode (ex: &copy; -> Â©)\n",
    "from html import unescape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import neattext as nt  # needed for text cleaning\n",
    "import numpy as np  # array processing\n",
    "import pandas as pd  # data analysis\n",
    "import tensorflow as tf  # we'll be using keras near the end of the notebook\n",
    "from better_profanity import profanity  # censor offensive words\n",
    "from nltk.tokenize import TweetTokenizer  # tokenizer\n",
    "# create a bag of words representation of the text data\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# scoring metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split # for splitting dataset into training and test sets\n",
    "\n",
    "# set the seed to get reproducible results\n",
    "SEED_NUM = 24\n",
    "np.random.seed(SEED_NUM)\n",
    "tf.random.set_seed(SEED_NUM)\n",
    "\n",
    "# increase pandas column widths\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "# data paths\n",
    "DAVIDSON_DATA_PATH = './data/davidson/labeled_data.txt'\n",
    "HURTLEX_DATA_PATH = './data/hurtlex_EN.tsv'\n",
    "GLOVE_TWITTER_EMBEDDINGS_PATH = './models/embeddings/glove-twitter-200.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee08a69-71f7-41c4-a4e6-b57d7eff9789",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction \n",
    "\n",
    "In this assignment I will go through the steps of building a classifier that can detect hateful and offensive content in English.\n",
    "\n",
    "One of the reasons I chose to work on this topic is because I feel there is not enough being done to curb the rampant online harassment that people have to deal with on social media. Hate speech, racial slurs, offensive content, threats of violence, and unwanted sexual comments are against the terms of service of all major social media websites, and yet in some communities they are as common as cat gifs. \n",
    "\n",
    "Some reasons why people get harassed or threatened online are because of their gender, race, religion, sexual orientation, or political views. Of course, none of these are good reasons as to why you should be hostile towards someone, but many people do not realize this. The majority of online harassment occurs on social media websites [$^{1}$](https://www.pewresearch.org/internet/2021/01/13/the-state-of-online-harassment/), so the responsibility falls on these large tech companies to look after their users' safety and well-being. Unfortunately, these companies are not doing enough.\n",
    "\n",
    "Let's look at how Facebook moderates its content. Most of Facebook's content moderation team does not work directly for Facebook as they are outsourced, and there are not that many of them. [$^{3}$](https://www.forbes.com/sites/johnkoetsier/2020/06/09/300000-facebook-content-moderation-mistakes-daily-report-says/?sh=2e15774d54d0) Facebook uses a hybrid system to moderate their content. Content is input into an A.I. model and will be flagged for review if the model detects any content violating the platform's terms of service. (Users can also flag content for review) This model does prevent a lot of harmful content from being seen, but it clearly could be implemented better based on the amount of users experiencing harassment on the platform. This model is also used to filter spam, fake news, and adult content, but of course this type of content is still very common on Facebook. [$^{4}$](https://www.forbes.com/sites/traversmark/2020/03/21/facebook-spreads-fake-news-faster-than-any-other-social-website-according-to-new-research/) Given the low number of human moderators working with Facebook, only 15,000 for over 2.9 billion monthly active users, [$^{3}$](https://www.forbes.com/sites/johnkoetsier/2020/06/09/300000-facebook-content-moderation-mistakes-daily-report-says/?sh=2e15774d54d0) [$^{2}$](https://www.statista.com/statistics/264810/number-of-monthly-active-facebook-users-worldwide/) there is a huge burden on Facebook's classifier to correctly flag objectionable content.\n",
    "\n",
    "I will be working with English language data in this notebook but the same techniques can be applied to data in other languages. While there is hate speech and misinformation present in English language communities on social media, the problem is amplified in parts of the world that have pre-existing racial or religious tensions between people. The textbook example of this is Facebook's wildly irresponsible expansion into Myanmar. Over there Facebook was used to spread hatred and incite violence against the Rohingya people, a Muslim minority group. Fake news and hate speech, targeted at the Rohingya people, spread like wildfire on Facebook's platform, often resulting in real-world violence against them.[$^{6}$](https://apnews.com/article/technology-business-middle-east-religion-europe-a38da3ccd40ffae7e4caa450c374f796) Facebook has failed on every step of the way to moderate the content being posted in Myanmar and the results were unfortunately tragic and completely avoidable.\n",
    "\n",
    "**Note**: Due to the nature of this topic and the dataset used, this notebook will contain examples of language that could be considered to be offensive or vulgar by the reader. I have tried to minimize the amount of objectionable content by limiting the amount of times I preview the data and by using a python module that censors profanity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10bb0de-d990-4fd7-b103-0c9b8b36069d",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this assignment I will show how AI and natural language processing can be used for social good by building multiple versions of a hateful content classifier, with each version being more sophisticated than the next. \n",
    "\n",
    "My goals with this assignment is to tackle an interesting, yet somewhat niche problem and to hopefully create a product that can be put to good use. When I say that this is a niche problem I do not mean that online harassment is a rare phenomenon, I am just commenting on the fact that while researching this topic I did not find a lot of community or commercial interest in AI-related solutions to this problem. I did however, find multiple academic papers and datasets that try to tackle this issue. In particular, I find that the work being done by the Hate-Alert group in IIT Kharagpur [$^{5}$](https://hate-alert.github.io/) to be very promising. \n",
    "\n",
    "I suspect that corporations are not interested because there is not much financial incentive for them to develop a solution to this problem, and any solution would probably bring up issues of privacy and surveillance that these companies would like to avoid. The lack of a community-driven or open-source solution to this issue is disappointing. The technology obviously exists since Twitter, Facebook, and YouTube all have classifiers that can detect offensive content, and in this same notebook I will show you how you can build one of these yourself (it's not very hard).\n",
    "\n",
    "I can think of several use cases for a classifier like this:\n",
    "\n",
    "1. It can be used to help people moderate communities.\n",
    "\n",
    "2. It can be used to enforce the terms of service of a social media website or any website that has a large amount of user-generated content.\n",
    "\n",
    "3. It can be part of a browser extension that blocks hateful content from social media sites in a similar way that AdBlock blocks ads. (You can even give it a fun name like TrollBlock).\n",
    "\n",
    "4. It can be used to pre-screen DMs before you get a chance to see them. This can be helpful for some people, particularly public figures and content creators, but of course it brings up some privacy concerns which I will not address here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd16aa0-22cc-41d8-94af-cedb6f1cbeeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "### Hate Speech and Offensive Language Dataset by Davidson et. al\n",
    "\n",
    "This dataset was developed by researchers at Cornell University, who wanted to improve traditional hate speech classifiers which relied too much on offensive language detection and could not differentiate between the use of an offensive term and actual hate speech. This dataset makes a distinction between text that contains hate speech and offensive content, which should make hate speech classifiers more accurate when it comes to classifying text that is offensive yet is not considered hate speech. I will be using this dataset to identify instances of English language hate speech and offensive content. I chose this dataset because of its direct connection to the topic, and because it is interesting.\n",
    "\n",
    "This dataset contains around 24.8k English language tweets that can contain either hate speech or offensive language, and there are also tweets that contain neither. The classification of these tweets has been crowdsourced by a platform called CrowdFlower which is a data collection agency that seems to have been renamed to Figure Eight, and then acquired by an Australian data company named Appen in recent years.\n",
    "\n",
    "Since the line between hate speech and offensive language is not very well defined, and since not everyone agrees on what is offensive or not, datasets like these will always have a degree of bias or subjectivity. It seems that researchers are aware of this issue because I have noticed that some hate speech datasets have multiple people classifying each example. In this dataset each example is classfied by a group of 3 to 9 people. This 'wisdom of the crowd' approach will help with the inherent bias present in this domain, but of course it will not eliminate it.\n",
    "\n",
    "\n",
    "The columns of interest in this dataset are:\n",
    "\n",
    "| Name               | Type                  | Description                                                  |\n",
    "| ------------------ | --------------------- | ------------------------------------------------------------ |\n",
    "| count              | Integer               | Number of people who classified this tweet as containing hate speech, offensive language, or neither |\n",
    "| hate_speech        | Integer               | How many people classified this tweet as containing hate speech |\n",
    "| offensive_language | Integer               | How many people classified this tweet as containing offensive language |\n",
    "| neither            | Integer               | How many people classified this tweet as neither containing hate speech or offensive language |\n",
    "| class              | Integer (Categorical) | This number represents the what the majority of people classified this tweet as.<br/>      0 = hate speech<br/>      1 = offensive language<br/>      2 = neither |\n",
    "| tweet              | Text                  | The text content of the tweet                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c23699-ec08-419a-9d05-9edf528df0cd",
   "metadata": {},
   "source": [
    "# Evaluation Methodology \n",
    "\n",
    "#### Checking for Class Imbalance in the Davidson Dataset\n",
    "\n",
    "The choice of evaluation metrics will be fueled by whether or not there is a class imbalance included in this dataset. We can check this easily with pandas, and graph the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c656f9-c173-4fc8-9c26-dbda06aa90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset with pandas\n",
    "davidson_preview = pd.read_csv(DAVIDSON_DATA_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39955002-66b8-49a3-a464-379f2deee3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Offensive Language    19190\n",
       "Neither                4163\n",
       "Hate Speech            1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the count of each class, and rename the index for clarity\n",
    "class_count = davidson_preview['class'].value_counts().rename(index={\n",
    "    0: 'Hate Speech',\n",
    "    1: 'Offensive Language',\n",
    "    2: 'Neither'\n",
    "})\n",
    "\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "312e20f3-2810-4576-8362-621ebed026f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Offensive Language    0.774\n",
       "Neither               0.168\n",
       "Hate Speech           0.058\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class count as percentages\n",
    "(class_count / class_count.sum()).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809177c-ea84-4803-8354-781cfb917a33",
   "metadata": {},
   "source": [
    "So, we can see that this is a very imbalanced dataset with around 77% of the tweets containing offensive language, 17% containing non-offensive language, and only 6% containing hate speech.\n",
    "\n",
    "Let's make this class imbalance clearer by plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d02cd32-2f37-4299-911a-c5261cb2e133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Increase figure size\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Use the built-in plotting functionality of pandas to create a bar plot\n",
    "class_count.plot(kind='bar',\n",
    "                 rot=0,\n",
    "                 xlabel='Tweet Type',\n",
    "                 ylabel='Number of tweets',\n",
    "                 title='Class Imbalance in Davidson Dataset',\n",
    "                 fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49126cbe-fbe1-4fb6-be02-ebf8c2d53be2",
   "metadata": {},
   "source": [
    "### Metrics for Davidson Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b782b14-589a-461e-a9b0-1e9f75a2a736",
   "metadata": {},
   "source": [
    "Because of the massive class imbalance in this dataset we will not be focusing on accuracy as a metric. A high accuracy score on an imbalanced data is misleading, as you will see in the performance baseline section. We will be looking at the precision and recall scores of our classifiers when evaluating them. For this particular application I believe that having a high recall score is more important than a high precision score. Classifiers like these are usually used to flag user submitted content for review by a moderation team, who will decide whether the content is against the terms of service of the platform or not. Having a high recall is important to avoid potentially harmful content from appearing on the platform, whereas having a low precision will make the job of the content moderation team more difficult. We will mainly be looking at the F1 score, which is just the harmonic mean of the precision and recall scores. To get a high F1 score you will need to have high precision and recall scores.\n",
    "\n",
    "This dataset is also a multi-class dataset so we will need to take into account the averaged scores of the precision, recall, and F1 scores. For example, to calculate the F1 score of a classifier on this dataset we will need to calculate the F1 score for each class and then average the results. In practice, scikit-learn will just do that for us.\n",
    "\n",
    "#### Scikit-Learn Averaging Strategies\n",
    "\n",
    "Scikit-learn has different methods for calculating precision, recall, and F1 scores for multi-class problems and since these different methods could give you wildly different results it is worth talking about them. The three strategies I considered for problem are `micro`, `macro`, and `weighted`.\n",
    "\n",
    "##### Micro\n",
    "\n",
    "The `micro` strategy simply sums up the total amount of true positives, false positives, and false negatives when calculating precision and recall. It does not calculate the precision and recall scores for each class, and it does not take class imbalance into account.\n",
    "\n",
    "##### Macro\n",
    "\n",
    "The `macro` strategy calculates the precision and recall scores for each class and the resulting precision/recall score is the average of precision/recall score of each class. It does not take into account class imbalance.\n",
    "\n",
    "##### Weighted\n",
    "\n",
    "The `weighted` strategy is similar to the `macro` strategy but it takes class imbalance into account by giving a weight to each class based on how represented that class is in the test data.\n",
    "\n",
    "I mainly looked at the `macro` precision/recall/F1 score of the classifiers I built in this notebook because even though I am working with an imbalanced dataset, every class has equal importance. I want my classifier to be able to identify instances of each class correctly, but if I chose the `weighted` strategy I would be able to get a high F1 score by performing poorly in the hate speech class, but doing very well in the other two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747ee03-a27f-42b7-b9c1-fc89b3698b6a",
   "metadata": {},
   "source": [
    "# Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cfdddb-9869-46e0-a1c6-88a994ed9962",
   "metadata": {},
   "source": [
    "## Baseline Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48256ab5-4812-4798-a1d2-d5c527506079",
   "metadata": {},
   "source": [
    "We will be using two classifiers as baselines for the Davidson dataset, with one of them being more realistic than the other.\n",
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aecf28c-8324-4428-8263-5e6e7386f5d3",
   "metadata": {},
   "source": [
    "This classifier will classify every example as being offensive. It will have a surprisingly high accuracy score because of the class imbalance, but of course it is not a good classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2567575d-609a-4717-809d-5f3399e8d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# The sklearn DummyClassifier class makes it possible to create dumb classifiers like this\n",
    "dummy = DummyClassifier(strategy='constant', constant=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eaff1e8-e50f-4647-9cec-f0ede5d10e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's no need to split the dataset into training and test sets\n",
    "X = davidson_preview['tweet']\n",
    "y = davidson_preview['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1de464aa-292b-406c-9555-1326955dbda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.fit(X, y)  # does nothing\n",
    "\n",
    "# This will just be an array of 1s\n",
    "dummy_preds = dummy.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c0204e-1b3f-4ebd-bdd1-3e9b2599ec71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the 'predicitions'\n",
    "dummy_preds[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e53a3e-3a3e-4d57-92c1-2733cb554271",
   "metadata": {},
   "source": [
    "We'll now write a function that we will use throughout this notebook to evaluate our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c2e353-1cec-40d7-869b-5c8cd56d282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(classifier, X, y, print_results=True, averaging_strategy=\"macro\"):\n",
    "    \"\"\"\n",
    "    Computes several metrics to evaluate the performance of a scikit-learn classifier\n",
    "    The metrics calculated are [Accuracy, Precision, Recall, F1 Score]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classifier : scikit-learn classifier\n",
    "        The classifier used to generate predictions on the test set\n",
    "        \n",
    "    X : numpy array or pandas DataFrame\n",
    "        The test set\n",
    "        \n",
    "    y : numpy array or pandas Series\n",
    "        The labels for the test set\n",
    "        \n",
    "    print_results : bool, optional\n",
    "        Whether to print the metrics calculated \n",
    "        or to return them as a tuple, by default True\n",
    "        \n",
    "    averaging_strategy : str, optional\n",
    "        What averaging strategy to use for \n",
    "        multi-class problems, by default \"macro\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None or tuple\n",
    "        Returns nothing if print_results is True,\n",
    "        else returns a tuple of the metrics calculated\n",
    "    \"\"\"\n",
    "    preds = classifier.predict(X)\n",
    "\n",
    "    accuracy = accuracy_score(y, preds)\n",
    "    precision = precision_score(y, preds, average='macro')\n",
    "    recall = recall_score(y, preds, average='macro')\n",
    "    f1 = f1_score(y, preds, average='macro')\n",
    "\n",
    "    if print_results:\n",
    "        print(\"Accuracy: \", accuracy)\n",
    "        print(\"Precision: \", precision)\n",
    "        print(\"Recall: \", recall)\n",
    "        print(\"F1 Score: \", f1)\n",
    "    else:\n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92b52682-26a8-4162-b19b-8751db353905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7743211072105879\n",
      "Precision:  0.2581070357368626\n",
      "Recall:  0.3333333333333333\n",
      "F1 Score:  0.29093610473093334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\nlp-mid\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(dummy, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede9745-8496-44cb-93be-d7c16f01db10",
   "metadata": {},
   "source": [
    "So we get a high accuracy, but very poor precision, recall, and F1 scores.\n",
    "\n",
    "Let us see what a more realistic baseline looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921b5a1-9751-4461-8aca-f5ac5bfe1715",
   "metadata": {},
   "source": [
    "### Keyword Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c78ed-02ba-4cdc-ac11-e8d444fc7800",
   "metadata": {},
   "source": [
    "One of the earliest methods of text classification was based on keyword detection. The presence of a keyword in a document would tell you whether or not that document belongs to a certain class or not. This works well for simple problems, but is not well suited to more sophisticated issues like categorizing articles, detecting spam, hateful content, or fake news. In particular, these keyword-based classifiers tend to have high recall and low precision. Building a keyword-based classifier to detect hate speech would be particularly difficult because it is possible to use an offensive word in a non-hateful way, and it is also possible to be hateful without using an offensive word. Furthermore, the keyword list would have to be very comprehensive and continually updated to identify new words that are being used in an offensive context.\n",
    "\n",
    "We will build a basic keyword detection classifier based on a publicly available list of offensive words collected by hurtlex. The list seems to be very comprehensive with over 8,000 terms in the English lexicon. There is also additional information for each term in the lexicon, but we are only interested in the offensive terms. We will also use random choice to determine if a tweet containing an offensive word is classified as hate speech or as offensive language, since there is no other obvious way to do approach this problem using keyword detection alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743cc8de-695b-42ed-abc1-68ae566cbace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the hurtlex data and only select the word column\n",
    "hurtlex = pd.read_csv(HURTLEX_DATA_PATH, sep='\\t')['lemma']\n",
    "\n",
    "# Turn the list into a python set\n",
    "hurtlex = set(hurtlex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d05fea-d1f3-4ab6-9834-9e7c0541d7f3",
   "metadata": {},
   "source": [
    "I will not preview this list for obvious reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab504ee4-c64b-4848-8ce1-18f752066303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordClassifier:\n",
    "    \"\"\"\n",
    "    A classifier with a similar API to a scikit-learn classifier \n",
    "    that classifies documents based on the presence of a keyword.\n",
    "    \"\"\"\n",
    "    def __init__(self, keywords):\n",
    "        \"\"\"\n",
    "        Constructor for the Keyword classifier.\n",
    "        Uses a set of user provided keywords and \n",
    "        initializes a tokenizer from nltk\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        keywords : set or list\n",
    "            A set or list of keywords to use when classifying documents\n",
    "        \"\"\"\n",
    "        self.keywords = keywords\n",
    "\n",
    "        # Use nltk's specialized tweet tokenizer\n",
    "        self.tokenizer = TweetTokenizer(preserve_case=False).tokenize\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Dummy fit method that does nothing\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array\n",
    "            Array of string values\n",
    "            \n",
    "        y : numpy array\n",
    "            Labels for the features matrix\n",
    "        \"\"\"\n",
    "        pass  # do nothing\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Produce predictions on given data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array\n",
    "            Array of string values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy array\n",
    "            An array of predictions\n",
    "        \"\"\"\n",
    "\n",
    "        # We need to vectorize the _keyword_check method in order\n",
    "        # for it to work with numpy arrays\n",
    "        kw_check = np.vectorize(self._keyword_check)\n",
    "\n",
    "        # Produce predictions\n",
    "        preds = kw_check(X)\n",
    "        return preds\n",
    "\n",
    "    def _keyword_check(self, document):\n",
    "        \"\"\"\n",
    "        Tokenizes a document and checks if it\n",
    "        contains any keyword in self.keywords. \n",
    "        \n",
    "        Private method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        document : str\n",
    "            A single string value to check for keywords            \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            A prediction based on the presence of a keyword or not\n",
    "        \"\"\"\n",
    "\n",
    "        # Tokenize the document\n",
    "        tokens = self.tokenizer(document)\n",
    "\n",
    "        # Check every token to see if it contains a key word\n",
    "        for token in tokens:\n",
    "            if token in self.keywords:\n",
    "                # Random choice\n",
    "                return np.random.choice([0, 1])\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558ee79a-b273-4821-9662-67f0360c99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_clf = KeywordClassifier(hurtlex)\n",
    "\n",
    "kw_clf.fit(X, y)  # does nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f1e0ee1-d398-47aa-b023-87b1b0249d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.42069160311503856\n",
      "Precision:  0.401606285885126\n",
      "Recall:  0.40047703930431205\n",
      "F1 Score:  0.3370591947065739\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(kw_clf, X, y, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743fac2f-d19e-45e4-bcb7-7cffb3f642bc",
   "metadata": {},
   "source": [
    "The results are interesting. Compared to the dummy classifier our accuracy is much worse, but our precision, recall, and F1 scores have significantly improved.\n",
    "\n",
    "We can try to make this keyword-based classifier more sophisticated to try to improve the score, but we will likely not get a reasonable score. This approach is far too simplistic for this issue. It is clear that this is not a simple problem, so we will try to solve it with machine learning, but first we will have to preprocess the tweets in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cdcdb4-9725-4eb5-9706-0ad4d83833e3",
   "metadata": {},
   "source": [
    "## Preprocessing the Davidson Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7eca92-677f-47f5-aa7c-2518eed1cb14",
   "metadata": {},
   "source": [
    "Let's read the dataset and preview it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1721c8cd-a13e-4306-adc0-40b72c7038b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class\n",
       "0      3            0                   0        3      2\n",
       "1      3            0                   3        0      1\n",
       "2      3            0                   3        0      1\n",
       "3      3            0                   2        1      1\n",
       "4      6            0                   6        0      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv into a pandas DataFrame and use the new performant string data type for the text field\n",
    "davidson_preview = pd.read_csv(DAVIDSON_DATA_PATH,\n",
    "                               index_col=0).astype({'tweet': 'string'})\n",
    "\n",
    "# I am not previewing the tweet column because of offensive language\n",
    "preview_columns = davidson_preview.columns[:-1]\n",
    "\n",
    "davidson_preview[preview_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073ad74-fe4f-41c1-8ded-97f68f309c5d",
   "metadata": {},
   "source": [
    "Let's look closer at some of the tweets. I will be censoring the offensive language language that is present in some of these tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d8e534d-8a21-455f-877f-42eb6da81746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_tweets(dataset, speech_type, censor=True, num_examples=4):\n",
    "    \"\"\"\n",
    "    Helper function to preview tweets from the Davidson dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : pandas Dataframe\n",
    "        The Davidson dataset\n",
    "\n",
    "    speech_type : str\n",
    "        The class of tweet you want to see examples of.\n",
    "        Can be ['hate', 'offensive', 'neither]\n",
    "\n",
    "    censor : bool, optional\n",
    "        Whether to censor the tweets or not, by default True\n",
    "\n",
    "    num_examples : int, optional\n",
    "        The number of tweets you want to see, by default 4\n",
    "    \"\"\"\n",
    "\n",
    "    # Look up table for the different tweet classes\n",
    "    speech_types = {\n",
    "        'hate': 0,\n",
    "        'offensive': 1,\n",
    "        'neither': 2,\n",
    "    }\n",
    "\n",
    "    # Get the desired tweet class\n",
    "    speech_class = speech_types[speech_type]\n",
    "\n",
    "    # Boolean mask of tweets of class `speech_class`\n",
    "    mask = dataset['class'] == speech_class\n",
    "\n",
    "    # Get a random sample of tweets from the class `speech_class`\n",
    "    tweets = dataset[mask].sample(num_examples, random_state=SEED_NUM)['tweet']\n",
    "\n",
    "    # Censor the tweets if desired\n",
    "    if censor:\n",
    "        for tweet in tweets:\n",
    "            print(profanity.censor(unescape(tweet)), end=\"\\n\\n\")\n",
    "    else:\n",
    "        for tweet in tweets:\n",
    "            print(unescape(tweet), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a4aaa3b-45b1-43a0-9e9a-2d7e0001b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zimmerman we comin for yo life ****. http://t.co/KHdZ1vdnSK\n",
      "\n",
      "@GlitteredInPink hoe don't tweet me\n",
      "\n",
      "RT @Moisessp14: Look at u now u pregnant **** **** lol\n",
      "\n",
      "@King_Albert21 @Ceto_13 u pulled.that **** **** as spon as u put no **** lol\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preview_tweets(davidson_preview, 'hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dafaa640-8d6e-40b5-8a4e-d229d8a8dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You know a **** mad when she throw her drink ð now she got to find another **** to buy her another one\n",
      "\n",
      "RT @Males_Thoughts: No **** **** chick flick will ever be as sad as this movie http://t.co/o0sk0SM40f\n",
      "\n",
      "\"@midyWIDEY_: I'm rea start smacking **** period !\" Bluffin at its best\n",
      "\n",
      "wow im a ****????? nice to **** know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preview_tweets(davidson_preview, 'offensive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19e92c3d-e33b-4a0b-b429-3ed7d9e5caf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @dallywaggz12: â@JustReIatabIe: Charlie Sheen gets point for this http://t.co/V6v0d77oBMâ\n",
      "\n",
      "RT @zippy1981: @voretaq7 from a TDD POV linux is just a mock for the kernel of the GNU/HURD system.\n",
      "\n",
      "Munching on ww crackers & studying NYCs trans syst. Since NYC & I haven't had a thing in over 15 yrs #clubinsomnia #vacay\n",
      "\n",
      "Friends don't let friends become guidos. #themoreyouknow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preview_tweets(davidson_preview, 'neither')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482aa16e-0848-45a7-a8bf-a9b71be39f20",
   "metadata": {},
   "source": [
    "Since this dataset only contains tweets, there is a lot of twitter specific information that could cause our classifiers to learn the noise rather than the actual English language. Things like URLs, @ symbols, and the RT at the start of a retweet. We will have to remove this noise before training a classifier on it. Other ways to remove noise from text data is by removing punctuation marks, capital letters, and stop words. Stop words are commonly used words in the English language that, by themselves, do not provide a text classifier with much information. The NLTK module comes with a list of stop words that can be used to filter text with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bc929fa-b44f-4d68-8a82-20222bdb2a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get the list of stopwords from nltk\n",
    "eng_stopwords = stopwords.words('english')\n",
    "\n",
    "# Preview some of them\n",
    "print(eng_stopwords[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa998d-d941-4624-a355-bfd8cd13a690",
   "metadata": {},
   "source": [
    "Here is an example of how you might remove stopwords from a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47de793a-0b7e-44db-9cfd-9551f2fceb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You great person I hope nice day\n"
     ]
    }
   ],
   "source": [
    "example_sent = 'You are a great person and I hope you have a nice day'\n",
    "\n",
    "example_tokens = example_sent.split(' ')\n",
    "\n",
    "# Filter the words with a list comprehension\n",
    "filtered_tokens = [word for word in example_tokens if word not in eng_stopwords]\n",
    "\n",
    "filtered_sent = ' '.join(filtered_tokens)\n",
    "\n",
    "print(filtered_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033aa3d-5708-4b06-953d-2c2439bec712",
   "metadata": {},
   "source": [
    "In the above code block we converted our example sentence into tokens by splitting on a single whitespace charater. This process is called tokenization, and it is needed to create a bag of words representation of our text. Splitting on a single whitespace worked for the above example, but it will not work quite as well when there are multiple whitespaces, line breaks, contractions, or odd punctuation. All of these are common on twitter and luckily for us NLTK actuallly comes with a tokenizer made specifically for tweets. Here is how you might use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9e742cf-a171-4a83-9517-b772525546d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"@FunnyPicsDepot: this the \"I play soccer, cheat on girls, and wear khaki coloured cargos\" haircut http://t.co/ZUai7qWBIR\" ð yup\n",
      "\n",
      "Tokens =  ['\"', ':', 'this', 'the', '\"', 'i', 'play', 'soccer', ',', 'cheat', 'on', 'girls', ',', 'and', 'wear', 'khaki', 'coloured', 'cargos', '\"', 'haircut', 'http://t.co/ZUai7qWBIR', '\"', 'ð', 'yup']\n"
     ]
    }
   ],
   "source": [
    "# Boolean mask of non offensive tweets \n",
    "non_offensive = davidson_preview['class'] == 2\n",
    "\n",
    "# One example of a non offensive tweet\n",
    "example_tweet = unescape(davidson_preview[non_offensive]['tweet'].iloc[12])\n",
    "\n",
    "print(example_tweet, end=\"\\n\\n\")\n",
    "\n",
    "# Initializing nltk's TweetTokenizer class\n",
    "tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                           reduce_len=True,\n",
    "                           strip_handles=True,\n",
    "                           match_phone_numbers=False)\n",
    "\n",
    "# Tokenize the tweet\n",
    "tokenized_tweet = tokenizer.tokenize(example_tweet)\n",
    "\n",
    "print(\"Tokens = \", tokenized_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94daed53-0f0f-4051-9bc9-38dc3029a90b",
   "metadata": {},
   "source": [
    "We can see that the tokenizer removed the @ mentions from twitter and did a good job with tokenizing the tweet, except for recognizing some punctuation as actual tokens. We do not want punctuation to be included in our tokens so we will have to remove punctuation from the tweets before tokenizing.\n",
    "\n",
    "I will use a python module named neattext to do a lot of the text cleaning in this assignment. Below is a demonstration of neattext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0665c74-f996-4918-b93b-2110d9220f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@FunnyPicsDepot: this the I play soccer cheat on girls and wear khaki coloured cargos haircut http://tco/ZUai7qWBIR ð yup'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We imported the neatext module as nt earlier\n",
    "\n",
    "nt.remove_puncts(example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4796fd38-cfb6-412b-9fdd-5baac139ff51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"@FunnyPicsDepot: this the \"I play soccer, cheat on girls, and wear khaki coloured cargos\" haircut  ð yup'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt.remove_urls(example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc268010-dd38-46b6-875f-184d2ba41772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@funnypicsdepot: this the i play soccer cheat on girls and wear khaki coloured cargos haircut http://tco/zuai7qwbir yup'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do all of the above (and more) in one function\n",
    "nt.clean_text(example_tweet,\n",
    "              urls=True,\n",
    "              puncts=True,\n",
    "              emails=True,\n",
    "              stopwords=False,\n",
    "              contractions=True,\n",
    "              multiple_whitespaces=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc347a6-1e42-4785-96e9-9145af716b9b",
   "metadata": {},
   "source": [
    "We are going to be creating a custom text cleaning transformer so we can use it in scikit-learn pipelines. Pipelines make things like hyper-parameter tuning and model selection much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56cc65dd-6ac6-435c-80df-d1a31482c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is helpful when you want to call a \n",
    "# function with specific arguments\n",
    "from functools import partial\n",
    "\n",
    "# We need to inherit from these two clases to\n",
    "# be able to create a scikit-learn transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom text cleaning scikit-learn transformer\n",
    "\n",
    "    Inherits from: BaseEstimator, TransformerMixin\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Dummy fit method.\n",
    "        Does nothing but is needed.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array or pandas DataFrame\n",
    "            Array of string values\n",
    "\n",
    "        y : numpy array, optional\n",
    "            Labels for X, by default None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        TextCleaner\n",
    "            Returns its own instance\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Cleans an array of text by removing punctuation, urls, \n",
    "        emails, contractions, and multiple whitespaces.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array or pandas DataFrame/Series\n",
    "            Array of string values\n",
    "\n",
    "        y : numpy array, optional\n",
    "            Labels for X, by default None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy array or pandas DataFrame/Series\n",
    "            A copy of X with clean text\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError\n",
    "            A TypeError is raised if X is not a numpy array or pandas DataFrame/Series\n",
    "        \"\"\"\n",
    "\n",
    "        # Use partial to define a clean_text function with specific arguments\n",
    "        clean_func = partial(nt.clean_text,\n",
    "                             urls=True,\n",
    "                             emails=True,\n",
    "                             contractions=True,\n",
    "                             stopwords=False,\n",
    "                             multiple_whitespaces=True)\n",
    "        \n",
    "        # Make a copy of X so that we do not modify the original matrix/array\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        # Check if X is a DataFrame/Series or numpy array\n",
    "        if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "            \n",
    "            # Convert HTML character entities to unicode\n",
    "            X_unicode = X_copy.map(unescape)\n",
    "\n",
    "            # Clean the text with clean_func\n",
    "            # Note: I have discovered that it is better to call remove_punctuation\n",
    "            # separately instead of using it with the clean_text function\n",
    "            X_clean = X_unicode.map(clean_func).map(nt.remove_puncts)\n",
    "\n",
    "            return X_clean\n",
    "\n",
    "        elif isinstance(X, np.ndarray):\n",
    "            # If X is a numpy array then we have to vectorize \n",
    "            # some functions in order for them to work with arrays\n",
    "            vec_unescape = np.vectorize(unescape)\n",
    "            vec_clean = np.vectorize(clean_func)\n",
    "            vec_rm_puncts = np.vectorize(nt.remove_puncts)\n",
    "\n",
    "            X_unicode = vec_unescape(X_copy)\n",
    "            X_clean = vec_rm_puncts(vec_clean(X_unicode))\n",
    "\n",
    "            return X_clean\n",
    "\n",
    "        else:\n",
    "            # Raise TypeError if X is neither a numpy array or pandas DataFrame/Series\n",
    "            raise TypeError(\n",
    "                'X has to be a pandas DataFrame/Series or numpy array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e46c3f5-f5c3-497e-aa8b-740e40b6b251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@funnypicsdepot: this the i play soccer cheat on girls and wear khaki coloured cargos haircut yup\n",
      "@funnypicsdepot: this the i play soccer cheat on girls and wear khaki coloured cargos haircut yup\n",
      "ERROR: X has to be a pandas DataFrame/Series or numpy array\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of TextCleaner\n",
    "text_cleaner = TextCleaner()\n",
    "\n",
    "print(text_cleaner.fit_transform(np.array([example_tweet]))[0])  # numpy array\n",
    "print(text_cleaner.fit_transform(pd.Series([example_tweet])).iloc[0])  # pandas Series\n",
    "\n",
    "try:\n",
    "    text_cleaner.fit_transform([example_tweet])  # raises error because X is a list\n",
    "except TypeError as e:\n",
    "    print('ERROR:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06ae66e3-1da3-475b-a22b-c6dc0cd8d2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@funnypicsdepot: this the i play soccer cheat on girls and wear khaki coloured cargos haircut yup\n",
      "\n",
      "Tokens =  [':', 'this', 'the', 'i', 'play', 'soccer', 'cheat', 'on', 'girls', 'and', 'wear', 'khaki', 'coloured', 'cargos', 'haircut', 'yup']\n"
     ]
    }
   ],
   "source": [
    "# Get a cleaned version of a tweet\n",
    "cleaned_tweet = text_cleaner.fit_transform(pd.Series([example_tweet])).iloc[0]\n",
    "\n",
    "print(cleaned_tweet, end=\"\\n\\n\")\n",
    "\n",
    "# Tokenize the the cleaned tweet\n",
    "print('Tokens = ', tokenizer.tokenize(cleaned_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db054a6-fd2c-44aa-ae7a-e4b01dd3f3bf",
   "metadata": {},
   "source": [
    "It is a bit annoying that a colon is being treated as a token. In the grand scheme of things this isn't that important since we will not be training our model on tokens that occur very commonly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7251fd-484c-437e-8b2e-baa3f5288520",
   "metadata": {},
   "source": [
    "To actually train our model on this cleaned up text data we still need to represent our data in a format that a machine learning algorithm can understand. We will use a bag of words model to represent our data for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90dc21d-bb7c-4107-8a5c-3db478c7a5c7",
   "metadata": {},
   "source": [
    "#### Bag of Words\n",
    "\n",
    "We will be using the below toy dataset to explain bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d798b8e8-5bcd-40da-92b1-61415dae2868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>loves_apples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apples are the best they really are</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i dont really like apples</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is wrong with you, apples are delicious</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i ate an apple yesterday and i hated it</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text  loves_apples\n",
       "0           apples are the best they really are          True\n",
       "1                     i dont really like apples         False\n",
       "2  what is wrong with you, apples are delicious          True\n",
       "3       i ate an apple yesterday and i hated it         False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example sentiment analysis dataset involving apples\n",
    "apples = pd.DataFrame({\n",
    "    'text': [\n",
    "        'apples are the best they really are', 'i dont really like apples',\n",
    "        'what is wrong with you, apples are delicious',\n",
    "        'i ate an apple yesterday and i hated it'\n",
    "    ],\n",
    "    'loves_apples': [True, False, True, False],\n",
    "})\n",
    "\n",
    "apples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920dacc-1172-4b81-9a26-239e3a1938b4",
   "metadata": {},
   "source": [
    "We will get an error if we try to train a model on this data. A machine learning model will not understand what to do with the data as they usually work with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39e88330-bfb4-43ce-864d-4f059d3402df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: could not convert string to float: 'apples are the best they really are'\n"
     ]
    }
   ],
   "source": [
    "# Import a naive bayes classifier from scikit-learn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create an instance of the classifier\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Define our features matrix and labels\n",
    "X, y = apples['text'], apples['loves_apples']\n",
    "\n",
    "try:\n",
    "    # Train our model on X and y\n",
    "    nb.fit(X, y)  # raises error!\n",
    "except ValueError as e:\n",
    "    print('ERROR:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca280799-2d21-48c3-9f9a-8307c32d69d6",
   "metadata": {},
   "source": [
    "We will have to convert the text data into a matrix of shape `(num_documents, vocab_size)`. Each row represents a sentence/tweet/document and each column represents a word. The value of the `(x, y)` element of a bag of words represents how many times the word y occurred in document x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72695989-b378-4b07-8961-5f5d920a5002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>apple</th>\n",
       "      <th>apples</th>\n",
       "      <th>are</th>\n",
       "      <th>ate</th>\n",
       "      <th>best</th>\n",
       "      <th>delicious</th>\n",
       "      <th>dont</th>\n",
       "      <th>hated</th>\n",
       "      <th>...</th>\n",
       "      <th>it</th>\n",
       "      <th>like</th>\n",
       "      <th>really</th>\n",
       "      <th>the</th>\n",
       "      <th>they</th>\n",
       "      <th>what</th>\n",
       "      <th>with</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   an  and  apple  apples  are  ate  best  delicious  dont  hated  ...  it  \\\n",
       "0   0    0      0       1    2    0     1          0     0      0  ...   0   \n",
       "1   0    0      0       1    0    0     0          0     1      0  ...   0   \n",
       "2   0    0      0       1    1    0     0          1     0      0  ...   0   \n",
       "3   1    1      1       0    0    1     0          0     0      1  ...   1   \n",
       "\n",
       "   like  really  the  they  what  with  wrong  yesterday  you  \n",
       "0     0       1    1     1     0     0      0          0    0  \n",
       "1     1       1    0     0     0     0      0          0    0  \n",
       "2     0       0    0     0     1     1      1          0    1  \n",
       "3     0       0    0     0     0     0      0          1    0  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This sklearn function can create a bag of words for us\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "\n",
    "# Produce the bag of words\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "\n",
    "# Get the column names\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# CountVectorizer returns a sparse matrix\n",
    "# we turn it into a dense one to use it with pandas\n",
    "pd.DataFrame(X_bow.todense(), columns=vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a69b0e-c037-4cbe-8186-3a11cb9938ee",
   "metadata": {},
   "source": [
    "We usually get better results by using a TF-IDF (Term Frequency - Inverse Document Frequency) vectorizer because it takes into account the relative rarity of a word within the entire dataset. In our apples dataset, the word 'apples' is included in every sentence so its inverse document frequency (rarity) will be low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a951719-9299-49d9-a936-d186d6bf02a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>apple</th>\n",
       "      <th>apples</th>\n",
       "      <th>are</th>\n",
       "      <th>ate</th>\n",
       "      <th>best</th>\n",
       "      <th>delicious</th>\n",
       "      <th>dont</th>\n",
       "      <th>hated</th>\n",
       "      <th>...</th>\n",
       "      <th>it</th>\n",
       "      <th>like</th>\n",
       "      <th>really</th>\n",
       "      <th>the</th>\n",
       "      <th>they</th>\n",
       "      <th>what</th>\n",
       "      <th>with</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250061</td>\n",
       "      <td>0.617751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.308875</td>\n",
       "      <td>0.391769</td>\n",
       "      <td>0.391769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.453005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240752</td>\n",
       "      <td>0.297376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377184</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377184</td>\n",
       "      <td>0.377184</td>\n",
       "      <td>0.377184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         an       and     apple    apples       are       ate      best  \\\n",
       "0  0.000000  0.000000  0.000000  0.250061  0.617751  0.000000  0.391769   \n",
       "1  0.000000  0.000000  0.000000  0.366747  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.240752  0.297376  0.000000  0.000000   \n",
       "3  0.377964  0.377964  0.377964  0.000000  0.000000  0.377964  0.000000   \n",
       "\n",
       "   delicious     dont     hated  ...        it     like    really       the  \\\n",
       "0   0.000000  0.00000  0.000000  ...  0.000000  0.00000  0.308875  0.391769   \n",
       "1   0.000000  0.57458  0.000000  ...  0.000000  0.57458  0.453005  0.000000   \n",
       "2   0.377184  0.00000  0.000000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "3   0.000000  0.00000  0.377964  ...  0.377964  0.00000  0.000000  0.000000   \n",
       "\n",
       "       they      what      with     wrong  yesterday       you  \n",
       "0  0.391769  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "2  0.000000  0.377184  0.377184  0.377184   0.000000  0.377184  \n",
       "3  0.000000  0.000000  0.000000  0.000000   0.377964  0.000000  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=0)\n",
    "\n",
    "# Produce the TF-IDF bag of words representation\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Get the column names\n",
    "vocabulary = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "pd.DataFrame(X_tfidf.todense(), columns=vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae774269-daee-4175-8815-207c5990e2c8",
   "metadata": {},
   "source": [
    "We can now train our classifier on our apples dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e932d2b4-3cdc-460f-97a2-b92c0e256512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_tfidf, y)  # does not raise an error\n",
    "\n",
    "# Make a prediction\n",
    "nb.predict(tfidf_vectorizer.transform(np.array(['apples are not good'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60afef-4abc-4f62-b80e-dd6cea148fca",
   "metadata": {},
   "source": [
    "We were able to train our model on this dataset and make a (wrong) prediction. While this is of course a toy problem the same techniques will be used on our hate speech dataset.\n",
    "\n",
    "The above examples don't take into account the ordering or the combination of certain words, so there is a loss of information. One method of solving this is to use n-grams, where n is a positive integer. An example of a 2-gram of the sentence \"I love apples a lot\" is:\n",
    "[\"I love\", \"love apples\", \"apples a\", \"a lot\"]\n",
    "\n",
    "You can add n-grams to your bag of words representation very easily just by using the `ngram_range` argument of the `TfidfVectorizer` or the `CountVectorizer`. Doing this usually gives us better results at the cost of ballooning the size of our features matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4cce611-2cd6-466d-ade1-edbc3040b8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>an apple</th>\n",
       "      <th>an apple yesterday</th>\n",
       "      <th>and</th>\n",
       "      <th>and hated</th>\n",
       "      <th>and hated it</th>\n",
       "      <th>apple</th>\n",
       "      <th>apple yesterday</th>\n",
       "      <th>apple yesterday and</th>\n",
       "      <th>apples</th>\n",
       "      <th>...</th>\n",
       "      <th>with you apples</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrong with</th>\n",
       "      <th>wrong with you</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yesterday and</th>\n",
       "      <th>yesterday and hated</th>\n",
       "      <th>you</th>\n",
       "      <th>you apples</th>\n",
       "      <th>you apples are</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.225586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         an  an apple  an apple yesterday       and  and hated  and hated it  \\\n",
       "0  0.000000  0.000000            0.000000  0.000000   0.000000      0.000000   \n",
       "1  0.000000  0.000000            0.000000  0.000000   0.000000      0.000000   \n",
       "2  0.000000  0.000000            0.000000  0.000000   0.000000      0.000000   \n",
       "3  0.235702  0.235702            0.235702  0.235702   0.235702      0.235702   \n",
       "\n",
       "      apple  apple yesterday  apple yesterday and    apples  ...  \\\n",
       "0  0.000000         0.000000             0.000000  0.154187  ...   \n",
       "1  0.000000         0.000000             0.000000  0.225261  ...   \n",
       "2  0.000000         0.000000             0.000000  0.143989  ...   \n",
       "3  0.235702         0.235702             0.235702  0.000000  ...   \n",
       "\n",
       "   with you apples     wrong  wrong with  wrong with you  yesterday  \\\n",
       "0         0.000000  0.000000    0.000000        0.000000   0.000000   \n",
       "1         0.000000  0.000000    0.000000        0.000000   0.000000   \n",
       "2         0.225586  0.225586    0.225586        0.225586   0.000000   \n",
       "3         0.000000  0.000000    0.000000        0.000000   0.235702   \n",
       "\n",
       "   yesterday and  yesterday and hated       you  you apples  you apples are  \n",
       "0       0.000000             0.000000  0.000000    0.000000        0.000000  \n",
       "1       0.000000             0.000000  0.000000    0.000000        0.000000  \n",
       "2       0.000000             0.000000  0.225586    0.225586        0.225586  \n",
       "3       0.235702             0.235702  0.000000    0.000000        0.000000  \n",
       "\n",
       "[4 rows x 60 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=0, ngram_range=(1, 3))\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "vocabulary = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "pd.DataFrame(X_tfidf.todense(), columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b166fb4-d97f-45fc-875b-f86bda7838ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_tfidf, y)\n",
    "\n",
    "nb.predict(tfidf_vectorizer.transform(np.array(['apples are not good'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290bab6-15f1-4ea6-97de-4b688d493de7",
   "metadata": {},
   "source": [
    "We still get a wrong prediction but obviously our model did not have the opportunity to learn much with this limited dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f922e-46ff-4483-8ba9-fd5475e3f8e1",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05944e1-1a10-4a63-a5a7-265eb7f71c65",
   "metadata": {},
   "source": [
    "One additional thing that we can do to improve our bag of words representation is to use stemming. You may have noticed that in the above apples dataset, the word `apple` and `apples` are treated as two different terms, yet they refer to the same concept. We can remedy this issue by stemming the tokens in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dceda951-0d17-4cbf-a42b-b7a38d2dfa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appl\n",
      "appl\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Use a stemmer that comes with nltk\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Both apples and apple have the stem appl\n",
    "print(stemmer.stem('apples'))\n",
    "print(stemmer.stem('apple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88922793-2c42-4ec7-aa84-8a9bc39cecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apple_tokenize(document):\n",
    "    \"\"\"\n",
    "    Basic tokenizer for the apples dataset\n",
    "    that also stems each token.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document : str\n",
    "        A single string value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of stemmed tokens\n",
    "    \"\"\"\n",
    "    tokens = document.split(' ')\n",
    "    tokens_stemmed = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3de5de8c-033e-475b-9c8c-f4cb74e5c38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>an appl</th>\n",
       "      <th>an appl yesterday</th>\n",
       "      <th>and</th>\n",
       "      <th>and i</th>\n",
       "      <th>and i hate</th>\n",
       "      <th>appl</th>\n",
       "      <th>appl are</th>\n",
       "      <th>appl are delici</th>\n",
       "      <th>appl are the</th>\n",
       "      <th>...</th>\n",
       "      <th>with you, appl</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrong with</th>\n",
       "      <th>wrong with you,</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yesterday and</th>\n",
       "      <th>yesterday and i</th>\n",
       "      <th>you,</th>\n",
       "      <th>you, appl</th>\n",
       "      <th>you, appl are</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126558</td>\n",
       "      <td>0.191207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118127</td>\n",
       "      <td>0.178469</td>\n",
       "      <td>0.226365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226365</td>\n",
       "      <td>0.226365</td>\n",
       "      <td>0.226365</td>\n",
       "      <td>0.226365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226365</td>\n",
       "      <td>0.226365</td>\n",
       "      <td>0.226365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.107060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         an   an appl  an appl yesterday       and     and i  and i hate  \\\n",
       "0  0.000000  0.000000           0.000000  0.000000  0.000000    0.000000   \n",
       "1  0.000000  0.000000           0.000000  0.000000  0.000000    0.000000   \n",
       "2  0.000000  0.000000           0.000000  0.000000  0.000000    0.000000   \n",
       "3  0.205158  0.205158           0.205158  0.205158  0.205158    0.205158   \n",
       "\n",
       "       appl  appl are  appl are delici  appl are the  ...  with you, appl  \\\n",
       "0  0.126558  0.191207         0.000000      0.242522  ...        0.000000   \n",
       "1  0.160925  0.000000         0.000000      0.000000  ...        0.000000   \n",
       "2  0.118127  0.178469         0.226365      0.000000  ...        0.226365   \n",
       "3  0.107060  0.000000         0.000000      0.000000  ...        0.000000   \n",
       "\n",
       "      wrong  wrong with  wrong with you,  yesterday  yesterday and  \\\n",
       "0  0.000000    0.000000         0.000000   0.000000       0.000000   \n",
       "1  0.000000    0.000000         0.000000   0.000000       0.000000   \n",
       "2  0.226365    0.226365         0.226365   0.000000       0.000000   \n",
       "3  0.000000    0.000000         0.000000   0.205158       0.205158   \n",
       "\n",
       "   yesterday and i      you,  you, appl  you, appl are  \n",
       "0         0.000000  0.000000   0.000000       0.000000  \n",
       "1         0.000000  0.000000   0.000000       0.000000  \n",
       "2         0.000000  0.226365   0.226365       0.226365  \n",
       "3         0.205158  0.000000   0.000000       0.000000  \n",
       "\n",
       "[4 rows x 66 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a tfidf vectorizer with a custom tokenizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=0,\n",
    "                                   ngram_range=(1, 3),\n",
    "                                   tokenizer=apple_tokenize)\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "vocabulary = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "pd.DataFrame(X_tfidf.todense(), columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8bb8d18-08dc-4bca-90b8-5ac3e4248e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_tfidf, y)\n",
    "\n",
    "nb.predict(tfidf_vectorizer.transform(np.array(['apples are not good'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f14a9-83a5-443c-b92a-f34a388a9fc2",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25754c9-8fe9-4b90-8a4c-02be4c10a600",
   "metadata": {},
   "source": [
    "One thing we will do to improve our machine learning model is to add sentiment analysis scores to the tweets. This is so our model learns more about each tweet other than the words that it contains. We will use the VADER library that comes with `nltk` to produce the sentiment analysis scores.\n",
    "\n",
    "The below code block shows the VADER library being used on the apples dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bef00cd-4802-4d25-95e7-155dff99e363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apples are the best they really are</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i dont really like apples</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is wrong with you, apples are delicious</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i ate an apple yesterday and i hated it</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text    neg    neu    pos  compound\n",
       "0           apples are the best they really are  0.000  0.588  0.412    0.6369\n",
       "1                     i dont really like apples  0.437  0.563  0.000   -0.3241\n",
       "2  what is wrong with you, apples are delicious  0.242  0.469  0.289    0.1531\n",
       "3       i ate an apple yesterday and i hated it  0.412  0.588  0.000   -0.6369"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def get_sentiment_df(text_column):\n",
    "    \"\"\"\n",
    "    Generates a DataFrame of sentiment analysis scores\n",
    "    using the VADER library\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text_column : pandas Series\n",
    "        A pandas Series of string values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas DataFrame\n",
    "        A DataFrame containing sentiment scores of each\n",
    "        sample in the text_column\n",
    "    \"\"\"\n",
    "    sentiment_scores = text_column.map(sentiment_analyzer.polarity_scores)\n",
    "\n",
    "    sentiment_df = pd.DataFrame()\n",
    "    sentiment_df['neg'] = sentiment_scores.map(lambda x: x['neg'])\n",
    "    sentiment_df['neu'] = sentiment_scores.map(lambda x: x['neu'])\n",
    "    sentiment_df['pos'] = sentiment_scores.map(lambda x: x['pos'])\n",
    "    sentiment_df['compound'] = sentiment_scores.map(lambda x: x['compound'])\n",
    "\n",
    "    return sentiment_df\n",
    "\n",
    "\n",
    "pd.concat([X, get_sentiment_df(X)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dee622-a58f-4128-8f73-2b483622415d",
   "metadata": {},
   "source": [
    "## Building The Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe51c7-ead0-4232-9d93-f6a41fe553f7",
   "metadata": {},
   "source": [
    "We will try out several machine learning classifiers with scikit-learn, and then we will move onto using more advanced techniques such as word embeddings and deep learning.\n",
    "\n",
    "While using scikit-learn I will take advantage of custom transformers and pipelines to enable easy model selection and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe478d-82bf-4a0a-993a-707b2d9987f3",
   "metadata": {},
   "source": [
    "For now I will create a custom tranformer to handle tokenization, stemming, vectorization, and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "557ea81d-002d-44a3-906d-9c59342f6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom Scikit-learn transformer that is \n",
    "    responsible for tokenization, stemming, vectorization,\n",
    "    and sentiment analysis.\n",
    "    \n",
    "    Inherits from: BaseEstimator, TransformerMixin\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 min_df=5,\n",
    "                 max_df=0.7,\n",
    "                 ngram_range=2,\n",
    "                 stop_words=True,\n",
    "                 idf=True,\n",
    "                 sentiment=True,\n",
    "                 stemming=True):\n",
    "        \"\"\"\n",
    "        FeatureExtractor class constructor\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        min_df: int or float < 1.0\n",
    "            Ignore terms that occur in less than min_df documents.\n",
    "            If float treat min_df as a percentage.\n",
    "        \n",
    "        max_df: int or float < 1.0\n",
    "            Ignore terms that occur in more than max_df documents.\n",
    "            If float treat max_df as a percentage.\n",
    "            \n",
    "        ngram_range: int\n",
    "            Set the maximum range to use for ngrams. If ngram_range = 3\n",
    "            the tokenizer will produce 1-grams, 2-grams, and 3-grams of the dataset.\n",
    "        \n",
    "        stop_words: bool\n",
    "            Whether to filter stopwords from the dataset or not. \n",
    "            If True the nltk list of stop words will be used.\n",
    "            \n",
    "        idf: bool\n",
    "            Whether to use idf weight values when vectorizing the dataset.\n",
    "            \n",
    "        sentiment: bool\n",
    "            Whether to use sentiment scores when transforming the dataset\n",
    "            \n",
    "        stemming: bool\n",
    "            Whether to use stemming when tokenizing the dataset\n",
    "        \"\"\"\n",
    "        self.idf = idf\n",
    "        self.stemming = stemming\n",
    "        self.sentiment = sentiment\n",
    "        self.stop_words = stop_words\n",
    "        self.min_df = min_df\n",
    "        self.max_df = max_df\n",
    "        self.ngram_range = ngram_range\n",
    "\n",
    "        # Define the tweet tokenizer\n",
    "        self.tweet_tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                                              reduce_len=True,\n",
    "                                              strip_handles=True,\n",
    "                                              match_phone_numbers=False).tokenize\n",
    "\n",
    "        # Define the stemmer (if using)\n",
    "        self.stemmer = PorterStemmer().stem if self.stemming else None\n",
    "        \n",
    "        # Define the sentiment_analyzer (if using)\n",
    "        self.sentiment_analyzer = SentimentIntensityAnalyzer() if self.sentiment else None\n",
    "\n",
    "        # Define the stopword list (if using)\n",
    "        self.stopword_list = stopwords.words('english') if self.stop_words else None\n",
    "        \n",
    "        # Define the vectorizer\n",
    "        self.vectorizer = TfidfVectorizer(min_df=self.min_df,\n",
    "                                          max_df=self.max_df,\n",
    "                                          ngram_range=(1, self.ngram_range),\n",
    "                                          stop_words=self.stopword_list,\n",
    "                                          use_idf=self.idf,\n",
    "                                          tokenizer=self._davidson_tokenizer)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit the vectorizer to the training set.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: numpy array or pandas DataFrame\n",
    "            Training set to fit the vectorizer on\n",
    "            \n",
    "        y: numpy array or pandas DataFrame\n",
    "            The labels of the training set.\n",
    "            y will not be used in this method so we set it to None\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        FeatureExtractor\n",
    "            This method will return its own instance like other scikit-learn\n",
    "            fit methods do.\n",
    "        \"\"\"\n",
    "        # Make a copy of the training set\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        # If the training set is a DataFrame convert to a numpy array\n",
    "        if isinstance(X_copy, pd.DataFrame):\n",
    "            X_copy = X_copy.to_numpy()\n",
    "\n",
    "        # Fit the vectorizer on the training set\n",
    "        self.vectorizer.fit(X_copy)\n",
    "        \n",
    "        # Returns an instance of itself\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Transform the training set into a format suitable for use with\n",
    "        machine learning algorithms.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pandas DataFrame\n",
    "            Training set to transform\n",
    "            \n",
    "        y: numpy array or pandas DataFrame\n",
    "            The labels of the training set.\n",
    "            y will not be used in this method so we set it to None\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        numpy array\n",
    "            Transformed feature matrix\n",
    "        \"\"\"\n",
    "        # Make a copy of X\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        # Vectorize X\n",
    "        X_transformed = self.vectorizer.transform(X_copy).todense()\n",
    "        \n",
    "        # Get the sentiment scores (if using)\n",
    "        if self.sentiment_analyzer:\n",
    "            sentiments = self._get_sentiment_df(X_copy)\n",
    "            X_transformed = np.c_[X_transformed, sentiments]\n",
    "\n",
    "        return X_transformed\n",
    "\n",
    "    def _davidson_tokenizer(self, value):\n",
    "        \"\"\"\n",
    "        Custom tokenizer for use with the TfidfVectorizer\n",
    "        Private method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        value: str\n",
    "            String value to tokenize and optionally stem\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "         list or numpy array of str values\n",
    "            A list or array of tokens\n",
    "        \"\"\"\n",
    "        # Tokenize with nltk's TweetTokenizer\n",
    "        tokens = self.tweet_tokenizer(value)\n",
    "        \n",
    "        # Optionally stem the tokens\n",
    "        if self.stemmer:\n",
    "            tokens_stemmed = [self.stemmer(token) for token in tokens]\n",
    "            return tokens_stemmed\n",
    "        else:\n",
    "            return tokens\n",
    "\n",
    "    def _get_sentiment_df(self, text_column):\n",
    "        \"\"\"\n",
    "        Uses the nltk VADER module to get the sentiment values of a pandas Series.\n",
    "        Private method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text_column: pandas Series of str values\n",
    "            The text values that we want to get the sentiment scores of\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        sentiment_df: pandas DataFrame\n",
    "            A DataFrame of the negative, neutral, positive, and compound scores of all the \n",
    "            values in the text_column\n",
    "        \"\"\"\n",
    "        sentiment_scores = text_column.map(self.sentiment_analyzer.polarity_scores)\n",
    "\n",
    "        sentiment_df = pd.DataFrame()\n",
    "        sentiment_df['neg'] = sentiment_scores.map(lambda x: x['neg'])\n",
    "        sentiment_df['neu'] = sentiment_scores.map(lambda x: x['neu'])\n",
    "        sentiment_df['pos'] = sentiment_scores.map(lambda x: x['pos'])\n",
    "\n",
    "        # Change the range of compound sentiment scores from (-1, 1) to (0, 1) because\n",
    "        # some classifiers do not support negative values (e.g. Naive Bayes)\n",
    "        sentiment_df['compound'] = sentiment_scores.map(\n",
    "            lambda x: np.interp(x['compound'], [-1, 1], [0, 1]))\n",
    "\n",
    "        return sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b5cb4-b685-422d-adbd-798066f9fc3f",
   "metadata": {},
   "source": [
    "We will start off with Naive Bayes which is a good classifier to use initially, because it trains fast and we do not have to worry about hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf1d2328-1a6d-4e23-963a-b72eb55388ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Naive Bayes Pipeline, including text cleaning, feature extraction, and Multinomial Naive bayes\n",
    "nb_pipeline = Pipeline([('cleaner', TextCleaner()),\n",
    "                        ('vectorizer', FeatureExtraction()),\n",
    "                        ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2026397c-077c-4fcb-9cce-e8e420e5c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the davidson dataset\n",
    "davidson = pd.read_csv(DAVIDSON_DATA_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45156b41-f41f-4bba-a9da-c8c9b7239f02",
   "metadata": {},
   "source": [
    "We will be using the cross_validate function with cv=5 which will train our model 5 times, with each time using a different subset of the dataset as the training set. Visually, it looks like this:\n",
    "\n",
    "- [**Test**] [Train] [Train] [Train] [Train]\n",
    "- [Train] [**Test**] [Train] [Train] [Train]\n",
    "- [Train] [Train] [**Test**] [Train] [Train]\n",
    "- [Train] [Train] [Train] [**Test**] [Train]\n",
    "- [Train] [Train] [Train] [Train] [**Test**]\n",
    "\n",
    "By averaging the results of the cross validation scores we get a good indicator of how well our model performs. Cross validation is particularly useful when there is not that much data to train on.\n",
    "\n",
    "**Note**: I have added `%%capture --no-display` to the top of some of these cells to suppress some numpy warnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2acf276-454d-4f5c-8b38-9dcb7b4f9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define our scoring metrics\n",
    "scoring_metrics = ['f1_macro', 'recall_macro', 'precision_macro', 'accuracy']\n",
    " \n",
    "nb_results = cross_validate(nb_pipeline,\n",
    "                            X=davidson['tweet'],\n",
    "                            y=davidson['class'],\n",
    "                            scoring=scoring_metrics,\n",
    "                            cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5ff91d9-0f4b-4b38-99ac-0db8d2a4cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5249384016957876\n"
     ]
    }
   ],
   "source": [
    "# We have to average the f1 scores for each cross validation fold\n",
    "print(np.mean(nb_results['test_f1_macro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a7c63-b8e2-4dee-9540-0479e51f287e",
   "metadata": {},
   "source": [
    "This is better than our baseline, but this is not a good score. Let us try a different classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52a9bba1-2c26-4e52-83c8-35f4c8dbc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Support Vector Machine pipeline including text cleaning, feature extraction, and LinearSVC\n",
    "svc_pipeline = Pipeline([('cleaner', TextCleaner()),\n",
    "                         ('vectorizer', FeatureExtraction()),\n",
    "                         ('clf', LinearSVC(random_state=SEED_NUM))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c006311-5844-4420-84d2-b48a92a850a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "svc_results = cross_validate(svc_pipeline,\n",
    "                             X=davidson['tweet'],\n",
    "                             y=davidson['class'],\n",
    "                             scoring=scoring_metrics,\n",
    "                             cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4be5f72c-1122-45ba-b271-7e60a34a124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7093959487681858\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(svc_results['test_f1_macro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30be25-bdf5-4a18-a8bb-33be68a5798d",
   "metadata": {},
   "source": [
    "By using a Linear Support Vector Classifier we get a much better score, let us see if we can improve it with some hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62dad56-a156-41f3-a4c8-71dc34164ad6",
   "metadata": {},
   "source": [
    "#### Improving our Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400c938-1a03-4fa1-957b-b2907c88ec93",
   "metadata": {},
   "source": [
    "We will perform some automatic hyperparameter tuning by defining a parameter grid that will be our search space and using RandomizedSearchCV to search through it. We will be using LinearSVC as our classifier, and most of the hyperparameters we are looking at will be related to the feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "542d5fd5-5b37-46d1-8b4a-4cccbe049da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search_pipeline = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('feature_extractor', FeatureExtraction()),\n",
    "    ('clf', LinearSVC(random_state=SEED_NUM)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_extractor__min_df': [2, 5],\n",
    "    'feature_extractor__ngram_range': [2, 3],\n",
    "    'feature_extractor__max_df': [0.4, 0.5, 0.6, 0.7],\n",
    "    'feature_extractor__stop_words': [True, False],\n",
    "    'feature_extractor__idf': [True, False],\n",
    "    'feature_extractor__stemming': [True, False],\n",
    "    'clf__C': [0.05, 0.1, 1.0, 10, 50, 100],\n",
    "}\n",
    "\n",
    "scoring_metrics = ['f1_macro', 'recall_macro', 'precision_macro', 'accuracy']\n",
    "\n",
    "random_search = RandomizedSearchCV(random_search_pipeline,\n",
    "                                   param_grid,\n",
    "                                   scoring=scoring_metrics,\n",
    "                                   refit='f1_macro',\n",
    "                                   cv=5,\n",
    "                                   n_iter=80,\n",
    "                                   random_state=SEED_NUM,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bca8feb2-856c-437b-bae5-c86cbbb0ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "# Run the search (takes a very long time)\n",
    "search_results = random_search.fit(davidson['tweet'], davidson['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c256c3-c091-41b8-84f4-c9f2de5b8ea3",
   "metadata": {},
   "source": [
    "The below code blocks will parse the results of the random search, to see what effect the different hyperparameters have on our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3063b805-6145-4441-bf0c-734d21206bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the results with pandas\n",
    "results_df = pd.DataFrame(search_results.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a304afd3-c7fe-4258-8a83-d8c7054f5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = [\n",
    "    'param_clf__C',\n",
    "    'param_feature_extractor__min_df',\n",
    "    'param_feature_extractor__max_df',\n",
    "    'param_feature_extractor__ngram_range',\n",
    "    'param_feature_extractor__stop_words',\n",
    "    'param_feature_extractor__idf',\n",
    "    'param_feature_extractor__stemming',\n",
    "    'mean_test_f1_macro',\n",
    "    'mean_test_recall_macro',\n",
    "    'mean_test_precision_macro',\n",
    "    'mean_test_accuracy',\n",
    "    'rank_test_f1_macro',\n",
    "]\n",
    "\n",
    "# We will use this dictionary to rename the columns for clarity\n",
    "columns_renamed = {\n",
    "    'param_clf__C': 'C',\n",
    "    'mean_test_f1_macro': 'F1 Score',\n",
    "    'mean_test_recall_macro': 'Recall',\n",
    "    'mean_test_precision_macro': 'Precision',\n",
    "    'mean_test_accuracy': 'Accuracy',\n",
    "    'rank_test_f1_macro': 'F1 Rank',\n",
    "    'param_feature_extractor__min_df': 'min_df',\n",
    "    'param_feature_extractor__max_df': 'max_df',\n",
    "    'param_feature_extractor__ngram_range': 'N-Gram Range',\n",
    "    'param_feature_extractor__stop_words': 'Stop Words',\n",
    "    'param_feature_extractor__idf': 'Use IDF',\n",
    "    'param_feature_extractor__stemming': 'Stemming'\n",
    "}\n",
    "results_df_copy = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "055abbed-39ee-4192-995a-d092d8a6c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and sort by f1 rank\n",
    "grid_search_summary_1 = results_df_copy[columns_of_interest].rename(columns=columns_renamed).sort_values(by='F1 Rank', ascending=True)\n",
    "\n",
    "# Save the results\n",
    "grid_search_summary_1.to_csv('./models/results/grid_search_results_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ebc3461-d092-4049-88a0-c68eadf33d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>N-Gram Range</th>\n",
       "      <th>Stop Words</th>\n",
       "      <th>Use IDF</th>\n",
       "      <th>Stemming</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.899</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.899</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.899</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  min_df  max_df  N-Gram Range  Stop Words  Use IDF  Stemming  \\\n",
       "0   1.0       5     0.7             2       False     True      True   \n",
       "52  1.0       5     0.5             3       False     True     False   \n",
       "69  1.0       5     0.6             3       False     True     False   \n",
       "8   1.0       5     0.5             2       False    False      True   \n",
       "74  1.0       5     0.5             3       False    False      True   \n",
       "51  1.0       2     0.4             2        True     True     False   \n",
       "73  1.0       2     0.4             2        True     True      True   \n",
       "3   1.0       5     0.4             3        True    False     False   \n",
       "50  1.0       2     0.6             2        True    False     False   \n",
       "78  1.0       5     0.7             2        True     True     False   \n",
       "36  1.0       5     0.4             2        True     True     False   \n",
       "57  1.0       2     0.6             3        True     True      True   \n",
       "37  0.1       5     0.5             3       False    False     False   \n",
       "56  0.1       5     0.7             2       False    False      True   \n",
       "34  0.1       5     0.4             2       False    False      True   \n",
       "\n",
       "    F1 Score  Recall  Precision  Accuracy  F1 Rank  \n",
       "0      0.709   0.693      0.759     0.896        1  \n",
       "52     0.709   0.693      0.759     0.896        1  \n",
       "69     0.709   0.693      0.759     0.896        1  \n",
       "8      0.709   0.693      0.759     0.896        1  \n",
       "74     0.709   0.693      0.759     0.896        1  \n",
       "51     0.709   0.693      0.759     0.896        1  \n",
       "73     0.709   0.693      0.759     0.896        1  \n",
       "3      0.709   0.693      0.759     0.896        1  \n",
       "50     0.709   0.693      0.759     0.896        1  \n",
       "78     0.709   0.693      0.759     0.896        1  \n",
       "36     0.709   0.693      0.759     0.896        1  \n",
       "57     0.709   0.693      0.759     0.896        1  \n",
       "37     0.677   0.659      0.803     0.899       13  \n",
       "56     0.677   0.659      0.803     0.899       13  \n",
       "34     0.677   0.659      0.803     0.899       13  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_1 = pd.read_csv('./models/results/grid_search_results_1.csv', index_col=0)\n",
    "\n",
    "grid_search_summary_1.head(15).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a96702-1d22-463d-b1a0-ab54295cdf6d",
   "metadata": {},
   "source": [
    "It looks like our randomized search was not able to improve on our default parameters, so we will just be using the default values from now on.\n",
    "\n",
    "We will now check if our model is overfitting. To do this we will need to create training and test sets.\n",
    "\n",
    "**Note**: While splitting the dataset into training and test sets we have to use the stratify option to ensure both sets have a similar class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63e3ec8a-e9c0-4869-8ff0-5883e1ef4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('feature_extractor', FeatureExtraction()),\n",
    "])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(davidson['tweet'],\n",
    "                                                    davidson['class'],\n",
    "                                                    train_size=0.9,\n",
    "                                                    random_state=SEED_NUM,\n",
    "                                                    stratify=davidson['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37693b13-9db3-4aac-9f17-afdaa28c043f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cleaner', TextCleaner()),\n",
       "                ('feature_extractor', FeatureExtraction())])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "preprocessing_pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e353d63-478e-4fcc-bd4f-583fcd6e9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess training and test sets\n",
    "X_train_processed = preprocessing_pipeline.transform(X_train)\n",
    "X_test_processed = preprocessing_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8335cdb7-9581-4ad5-81bf-2bb60584e66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=24)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "svc = LinearSVC(random_state=SEED_NUM)\n",
    "\n",
    "svc.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0d778a4-d06f-4390-891e-34b84f455131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\nlp-mid\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9520713773314203\n",
      "Precision:  0.9166653433970877\n",
      "Recall:  0.8216814926626088\n",
      "F1 Score:  0.8554408074677967\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(svc, X_train_processed, y_train, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99c18b17-90ce-4b46-b7be-493bd4253ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9072206534893102\n",
      "Precision:  0.7868903050354664\n",
      "Recall:  0.7027874902874903\n",
      "F1 Score:  0.7256491826794477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\nlp-mid\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(svc, X_test_processed, y_test, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d68598-6547-4ed2-b3c0-f370d12ca37d",
   "metadata": {},
   "source": [
    "Based on the disparity between the F1 scores, we are overfitting to our training set by a good amount. Lets try using a random forest classifier. I did not include this classifier in the grid search since I know it will take an unreasonable amount of time to train given the large amount of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6faf1d5-d9cb-4ab2-9449-e7cc0c17dfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\nlp-mid\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d94b788-5308-48f2-8e68-fd219e8e92b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\nlp-mid\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9958751793400287\n",
      "Precision:  0.9931032020148134\n",
      "Recall:  0.9877696945547404\n",
      "F1 Score:  0.9903870696382331\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(rf, X_train_processed, y_train, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4bae993-192c-430a-81a7-efcc367d2178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9019766034691408\n",
      "Precision:  0.7565895004851599\n",
      "Recall:  0.6458891802641803\n",
      "F1 Score:  0.6603061518336438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\nlp-mid\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(rf, X_test_processed, y_test, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1aaabd-be41-42b0-a209-241fe470d318",
   "metadata": {},
   "source": [
    "The score on the test set is actually worse, and we are still badly overfitting. If we look at the amount of features we have in our features matrix it is easy to see why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5377470b-841f-4a4f-a34d-3ad8d1423230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22304, 5954)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e15c5-497b-45fb-9a44-fadd6b6b78e1",
   "metadata": {},
   "source": [
    "We have around 6,000 features for each of our 22,300 training samples. This means that our features represent our training dataset too well which leads to overfitting.\n",
    "\n",
    "Unfortunately this is a consequence of the bag of words representation of the dataset, this large amount of features in our training dataset leads to models that do not generalize well to new data. Still, our F1 score of 0.725 on the test set using the linear SVC model is much greater than our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c5c20-c6a7-4148-9fa9-b0f3ff29cc20",
   "metadata": {},
   "source": [
    "## Word Embeddings: A Different Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560aa99-2940-47d8-86be-86d2426d8c2c",
   "metadata": {},
   "source": [
    "As we saw above bag of words representations tend to produce very high dimensional feature matrices that could lead to poor generalization on unseen data. Another approach to represent text data is by using word embeddings. A word embedding is a way of representing a word in a vector of relatively low number of dimensions (typically 100 to 300 dimensions). They are simply an array of floating point values that represent the semantic meaning of the word. Word embeddings are produced by training a model on a very large corpus of text data. Training word embeddings is an unsupervised machine learning task, the weights are learned by how many times certain words appear together in a corpus. We will not be training word any embeddings in this notebook we will just use word vectors that have been trained on a very large amount of twitter data (2 Billion tweets!). These word embeddings come from Stanford's Glove project found [here](https://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "Word embeddings are typically used with deep learning techniques, but it is possible to use them with scikit-learn classifiers. I will demonstrate this below but the results are not that great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2571e278-11b8-4c78-9ddb-9d9da245c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the zeugma library which makes using embeddings with scikit-learn easy\n",
    "from zeugma.embeddings import EmbeddingTransformer\n",
    "\n",
    "# We load an embedding transformer with weights from the Glove twitter embeddings\n",
    "glove_twitter = EmbeddingTransformer(model='glove-twitter-200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20794747-daa5-4856-b14b-55c9e9b12ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to do some text cleaning without using pipelines\n",
    "tweet_tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                                 reduce_len=True,\n",
    "                                 strip_handles=True,\n",
    "                                 match_phone_numbers=False).tokenize\n",
    "\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tokens = tweet_tokenizer(tweet)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "text_cleaner = TextCleaner()\n",
    "# Create a clean version of our dataset\n",
    "davidson_clean = text_cleaner.transform(davidson['tweet'].map(clean_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f272a585-e35a-488e-afda-80ae63618631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(davidson_clean,\n",
    "                                                    davidson['class'],\n",
    "                                                    train_size=0.9,\n",
    "                                                    random_state=SEED_NUM,\n",
    "                                                    stratify=davidson['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c852a726-461e-4031-a954-92192dda2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training and test sets using the zeugma embedding transformer \n",
    "X_train_processed = glove_twitter.transform(X_train)\n",
    "X_test_processed = glove_twitter.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "279dd79c-267e-4ed4-8765-db4005c0283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce sentiment scores\n",
    "X_train_sents = get_sentiment_df(X_train).to_numpy()\n",
    "X_test_sents = get_sentiment_df(X_test).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6dac5f74-648e-4d1d-9fe2-48a5b384faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join sentiment scores with the word embeddings\n",
    "X_train_processed = np.c_[X_train_processed, X_train_sents]\n",
    "X_test_processed = np.c_[X_test_processed, X_test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "14f8f31f-1f57-4f5f-b4f4-f92f408d1b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=24)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "svc = LinearSVC(random_state=SEED_NUM)\n",
    "\n",
    "# Start training\n",
    "svc.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "562019c2-3561-4dc7-81ae-1f1e0dafb99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8933375179340028\n",
      "Precision:  0.7779380482031861\n",
      "Recall:  0.641177090526634\n",
      "F1 Score:  0.6580725186730128\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(svc, X_train_processed, y_train, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b4f28523-dd0c-4d23-8633-16e26a6d96ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8935054457442517\n",
      "Precision:  0.7756939394248809\n",
      "Recall:  0.6397326631701632\n",
      "F1 Score:  0.6493965641032382\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(svc, X_test_processed, y_test, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bfc7f0-bb6f-4476-be22-99587bd2e176",
   "metadata": {},
   "source": [
    "We get a poor score using support vector machines, so lets try another classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4a82e4b6-74aa-4230-aee2-10f9cfc034a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, n_jobs=-1, random_state=24)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=SEED_NUM, max_iter=1000, n_jobs=-1)\n",
    "\n",
    "lr.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "01ec9e1f-f529-4aab-b5f9-74e6040da21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8981796987087518\n",
      "Precision:  0.783446786323006\n",
      "Recall:  0.6670718309685535\n",
      "F1 Score:  0.6909997539543614\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(lr, X_train_processed, y_train, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7f1582c0-d180-4936-9eeb-a6885015f85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8947156111335216\n",
      "Precision:  0.7382514849081163\n",
      "Recall:  0.6488830613830614\n",
      "F1 Score:  0.6628204601067081\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(lr, X_test_processed, y_test, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ca9fe-cc2f-476a-b01f-0272f1af6a75",
   "metadata": {},
   "source": [
    "By using word embeddings with \"shallow\" scikit-learn classifiers we are no longer badly overfitting to the training set, however the performance is not that good. So we will try a deep learning based approach. Word embeddings are commonly used in deep learning after all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3cd696-d492-4f63-8e89-9dd6fa5e7537",
   "metadata": {},
   "source": [
    "## Word Embeddings with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088bd3c4-a3d0-431c-bf7e-1ab9c2ccd0bf",
   "metadata": {},
   "source": [
    "We will be using tensorflow and keras to build our deep learning-based classifier. The process of loading word embeddings into a keras model is a bit involved. It helps to understand the format of the pretrained word embeddings. When you download the GLOVE twitter 200 dimension word embeddings they will be formatted like this:\n",
    "\n",
    "```\n",
    "donut 0.007 0.001 0.006 0.005 0.124 0.1004 ...\n",
    "\n",
    "bob 0.04 0.006 0.03 0.22 0.53 0.001  0.201 ...\n",
    "```\n",
    "\n",
    "In each line there will be a token (word) and then there is a list of floating point values representing the word embeddings themselves. In the case of the GLOVE embeddings we are working with, there are 200 floating point values for each token. The below code block loads the word embeddings into a dictionary.\n",
    "\n",
    "**Note**: Some of the code to load the word embeddings into keras, was adapted from the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73e19579-7d46-434c-8a1e-24b447d60bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary will hold the word embeddings\n",
    "embeddings_index = {}\n",
    "\n",
    "# Open the GLOVE embeddings file like a text file\n",
    "with open(GLOVE_TWITTER_EMBEDDINGS_PATH, encoding='utf-8') as f:\n",
    "    # Read each line of the embeddings file\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        # Tokenize the line\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "\n",
    "        # First token is the word\n",
    "        word = values[0]\n",
    "        \n",
    "        # The rest of the tokens are the weights\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "        # Add the word as the key and the array of weights as the value\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c046f1-d70b-4855-9b12-6e1172acca96",
   "metadata": {},
   "source": [
    "Now that we have the embeddings in a dictionary we can just load it into a keras Layer, but to actually train the model on our data we need to preprocess our text data into a format that keras can work with. The particular neural network architecture that we will be using (a bi-directional LSTM) works well with a sequence of integers, where each integer represents a word in our dataset. This format takes word order into account. The below code uses keras' preprocessing methods to transform our dataset into this format.\n",
    "\n",
    "**NOTE**: The code to preprocess our text data was adapted from this [Kaggle notebook](https://www.kaggle.com/vsmolyakov/keras-cnn-with-fasttext-embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5de46cf-5172-4d43-8224-f7b0073eafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(davidson_clean,\n",
    "                                                    davidson['class'],\n",
    "                                                    train_size=0.9,\n",
    "                                                    random_state=SEED_NUM,\n",
    "                                                    stratify=davidson['class'])\n",
    "\n",
    "# Initialize keras tokenizer\n",
    "tokenizer = Tokenizer(lower=True, char_level=False)\n",
    "\n",
    "# Fit the tokenizer\n",
    "tokenizer.fit_on_texts(davidson_clean)\n",
    "\n",
    "# Transform the training and test sets\n",
    "davidson_seq_train = tokenizer.texts_to_sequences(X_train)\n",
    "davidson_seq_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Get the word index produced by the tokenizer\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Make every vector in our training and test sets the same length\n",
    "# by padding them to the left with zeros\n",
    "davidson_seq_train = sequence.pad_sequences(davidson_seq_train)\n",
    "davidson_seq_test = sequence.pad_sequences(davidson_seq_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d70659-46d6-43e9-96fa-03057259e228",
   "metadata": {},
   "source": [
    "We will now create an embedding layer from our embeddings dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90b052fc-2a68-487c-bb7c-d4c2ea862c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty matrix to be loaded with embeddings\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 200))\n",
    "\n",
    "# Fill the matrix with embeddings for each word in the word index\n",
    "for word, i in word_index.items():\n",
    "    # Get the embeddings for the word\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    # Add the embedding to the matrix if it exists\n",
    "    if embedding_vector is not None and len(embedding_vector) > 0:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b692925c-44dd-4dfd-ac5b-7cca74971176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embedding matrix\n",
    "np.save('./models/embeddings/glove_200_embedding_matrix.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4a944a4c-752d-4b4e-86e5-4131141181ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding matrix\n",
    "embedding_matrix = np.load('./models/embeddings/glove_200_embedding_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23e57a96-c671-4a19-bfcb-ea1a9c90c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers, layers\n",
    "\n",
    "# Create the Embedding layer in keras\n",
    "embedding_layer = layers.Embedding(len(word_index) + 1,\n",
    "                                   200,\n",
    "                                   embeddings_initializer=initializers.Constant(embedding_matrix),\n",
    "                                   trainable=False,\n",
    "                                   mask_zero=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c5eb0-efc4-4e89-b668-a062ec98de94",
   "metadata": {},
   "source": [
    "We now have to build a model in keras. I have tried out some different architectures for this problem and I got the best results with a 2 stack of bi-directional LSTM layers with 64 hidden units and a dropout of 0.2. The code to build and train such a model is very straightforward.\n",
    "\n",
    "**Note**: I did not include my experiments with different architectures because I do not want this notebook to be too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d745739a-45e8-4ccb-95f1-5497ff68199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "inputs = Input(shape=(None,), dtype=\"int64\") # Input layer (this will be an array of integers)\n",
    "embedded = embedding_layer(inputs) # Embedding layer\n",
    "lstm_1 = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(embedded) # 1st LSTM layer\n",
    "lstm_1 = layers.Dropout(0.2)(lstm_1) # Dropout layer for regularization\n",
    "lstm_2 = layers.Bidirectional(layers.LSTM(64))(lstm_1) # 2nd LSTM layer\n",
    "lstm_2 = layers.Dropout(0.2)(lstm_2) # Dropout layer for regularization\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(lstm_2) # Output layer\n",
    "lstm_model = Model(inputs, outputs) # Define our model\n",
    "\n",
    "# Set the optimizer, loss function, and metrics\n",
    "lstm_model.compile(optimizer=\"adam\",\n",
    "                   loss=\"categorical_crossentropy\",\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "62f4af2f-867c-4a9f-9a2b-d388fb288596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# The LSTM layer expects our labels to be one hot encoded\n",
    "# so we will encode them with this keras function\n",
    "y_train_cat = to_categorical(y_train, 3)\n",
    "y_test_cat = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe767fa-ec38-42ec-9a0d-5434566eb1e5",
   "metadata": {},
   "source": [
    "It is now time to train our model. During training we can also use part of our training set as a validation set, and we can also tell keras to stop training if the score on the validation set is not improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "617f2dd9-a103-43df-8eab-a554781b1914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "628/628 [==============================] - 266s 407ms/step - loss: 0.3269 - accuracy: 0.8859 - val_loss: 0.2881 - val_accuracy: 0.8915\n",
      "Epoch 2/50\n",
      "628/628 [==============================] - 253s 403ms/step - loss: 0.2477 - accuracy: 0.9121 - val_loss: 0.2683 - val_accuracy: 0.8974\n",
      "Epoch 3/50\n",
      "628/628 [==============================] - 250s 398ms/step - loss: 0.2228 - accuracy: 0.9190 - val_loss: 0.2802 - val_accuracy: 0.9023\n",
      "Epoch 4/50\n",
      "628/628 [==============================] - 253s 402ms/step - loss: 0.1999 - accuracy: 0.9267 - val_loss: 0.2821 - val_accuracy: 0.9005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27003474460>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "lstm_model.fit(davidson_seq_train,\n",
    "               y_train_cat,\n",
    "               validation_split=0.1,\n",
    "               epochs=50,\n",
    "               callbacks=EarlyStopping(patience=2, restore_best_weights=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b3028-f983-4369-b86b-6589ee421595",
   "metadata": {},
   "source": [
    "Because this model seems to overfit really quickly lets retrain the model for only 3 epochs on the full training set (without splitting it for validation) and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "624d97b7-dddb-4a4a-8881-e27130856895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "697/697 [==============================] - 147s 200ms/step - loss: 0.3255 - accuracy: 0.8863\n",
      "Epoch 2/3\n",
      "697/697 [==============================] - 139s 200ms/step - loss: 0.2508 - accuracy: 0.9095\n",
      "Epoch 3/3\n",
      "697/697 [==============================] - 140s 200ms/step - loss: 0.2264 - accuracy: 0.9184 - loss: 0.2261 - accuracy: 0. - ETA: 0s - loss: 0.2260 - accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2709d22fc40>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to define the model again to reset the weights of each layer\n",
    "# and be able to train from scratch\n",
    "inputs = Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = embedding_layer(inputs)\n",
    "lstm_1 = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(embedded)\n",
    "lstm_1 = layers.Dropout(0.2)(lstm_1)\n",
    "lstm_2 = layers.Bidirectional(layers.LSTM(64))(lstm_1)\n",
    "lstm_2 = layers.Dropout(0.2)(lstm_2)\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(lstm_2)\n",
    "lstm_model = Model(inputs, outputs)\n",
    "lstm_model.compile(optimizer=\"adam\",\n",
    "                   loss=\"categorical_crossentropy\",\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "lstm_model.fit(\n",
    "    davidson_seq_train,\n",
    "    y_train_cat,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af9499-f63a-4cb4-ad46-2706da919ea4",
   "metadata": {},
   "source": [
    "We need to modify our evaluate_classifier function slightly because keras classifiers output probabilities for each class instead of the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "97a3f881-8eed-4967-b267-615826e0ed87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_keras_classifier(keras_classifier, X, true_vals, print_results=True, averaging_strategy='macro'):\n",
    "    \"\"\"\n",
    "    Computes several metrics to evaluate the performance of a keras classifier\n",
    "    The metrics calculated are [Accuracy, Precision, Recall, F1 Score]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    keras_classifier : keras classifier\n",
    "        The classifier used to generate predictions on the test set\n",
    "        \n",
    "    X : numpy array or pandas DataFrame\n",
    "        The test set\n",
    "        \n",
    "    y : numpy array or pandas Series\n",
    "        The labels for the test set\n",
    "        \n",
    "    print_results : bool, optional\n",
    "        Whether to print the metrics calculated \n",
    "        or to return them as a tuple, by default True\n",
    "        \n",
    "    averaging_strategy : str, optional\n",
    "        What averaging strategy to use for \n",
    "        multi-class problems, by default \"macro\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None or tuple\n",
    "        Returns nothing if print_results is True,\n",
    "        else returns a tuple of the metrics calculated\n",
    "    \"\"\"\n",
    "    preds = np.argmax(keras_classifier.predict(X), axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(true_vals, preds)\n",
    "    precision = precision_score(true_vals, preds, average=averaging_strategy)\n",
    "    recall = recall_score(true_vals, preds, average=averaging_strategy)\n",
    "    f1 = f1_score(true_vals, preds, average=averaging_strategy)\n",
    "\n",
    "    if print_results:\n",
    "        print(\"Accuracy: \", accuracy)\n",
    "        print(\"Precision: \", precision)\n",
    "        print(\"Recall: \", recall)\n",
    "        print(\"F1 Score: \", f1)\n",
    "    else:\n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ab4db03c-b98d-4d43-a74a-c8cfa70a3ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9213392496974586\n",
      "Precision:  0.8054834688494052\n",
      "Recall:  0.7544058372183372\n",
      "F1 Score:  0.7708874604793875\n"
     ]
    }
   ],
   "source": [
    "evaluate_keras_classifier(lstm_model,\n",
    "                          davidson_seq_test,\n",
    "                          y_test,\n",
    "                          print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8eb449-8e01-4097-a73b-742e74ac9a04",
   "metadata": {},
   "source": [
    "This is a significant improvement over our best scikit-learn classifier. Let us now save our model and move on to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c6de5730-9ed5-4b02-a90c-058e5f07e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('./models/lstm_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96bd523-f8f0-47ef-a894-6443a2bab02f",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686641ec-bbb6-4682-b5f3-868b17fa5fb9",
   "metadata": {},
   "source": [
    "Let's take a closer look at how our model performs and what mistakes it makes. A confusion matrix can help us visualize our model's performance on a test set so lets create one with scikit-learn and visualize it with seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "408916e7-a424-4f47-aaa5-39b3cec5bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model as load_keras_model\n",
    "\n",
    "# Load our keras model\n",
    "lstm_model = load_keras_model('./models/lstm_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2bff40e6-7d03-4a97-86a9-00615e5bc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = np.argmax(lstm_model.predict(davidson_seq_test), axis=1)\n",
    "\n",
    "# Create a confusion matrix\n",
    "# This will just be a numpy matrix that we will visualize later\n",
    "cm = confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aa3753f5-69cc-415a-bfa6-2930b285e4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Make our plot bigger\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Class names\n",
    "tick_labels = ['Hate Speech', 'Offensive Content', 'Neither']\n",
    "\n",
    "# Use seaborn's heatmap to plot our confusion matrix\n",
    "ax = sns.heatmap(cm,\n",
    "                 annot=True,\n",
    "                 annot_kws={'fontsize': 16},\n",
    "                 fmt='',\n",
    "                 xticklabels=tick_labels,\n",
    "                 yticklabels=tick_labels,\n",
    "                 cmap=sns.color_palette(\"magma_r\", as_cmap=True),\n",
    "                 cbar=False,\n",
    "                )\n",
    "\n",
    "# Label our graph\n",
    "ax.set_title('Hateful Content Classifier Confusion Matrix', fontsize=22)\n",
    "ax.set_xlabel('Predicted Label', fontsize=20)\n",
    "ax.set_ylabel('True Label', fontsize=20)\n",
    "ax.tick_params(labelsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3577f1-fa8d-4149-b8dc-28cf5b6c11fd",
   "metadata": {},
   "source": [
    "This is pretty helpful since it shows us where our model struggles. Our model performs poorly when classifying hate speech. In particular it seems to classify hate speech as offensive content more often than it does classify it as hate speech. The authors of this dataset built their own classifier that is described in the paper that accompanied the dataset, and in that paper their classifier also struggles with classifying hate speech.\n",
    "\n",
    "Let us try to get concrete numbers on how our model performs on classifying hate speech. We can get precision, recall, and f1 scores for each class by setting the averaging strategy to None. This will give us an array of scores for each class. They will be in this format:\n",
    "\n",
    "`['hate' score, 'offensive' score, 'neither' score]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f367cd93-d0f0-43ef-aace-913832f1058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the scores for each class by setting averaging strategy to None\n",
    "accuracy, precision_scores, recall_scores, f1_scores = evaluate_keras_classifier(lstm_model,\n",
    "                                                                                 davidson_seq_test,\n",
    "                                                                                 y_test,\n",
    "                                                                                 print_results=False,\n",
    "                                                                                 averaging_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b5e13209-48fb-423e-a129-2df0b79d83e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9213392496974586"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60255360-97da-4884-99f4-94781cfa91fd",
   "metadata": {},
   "source": [
    "We get a high accuracy but we are not relying on accuracy as a useful metric for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "99818cea-eaf8-4072-965b-b9a4213f955e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59550562, 0.94707091, 0.87387387])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b2c7cec1-20c8-4822-a6b5-5042987ea9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37062937, 0.95989583, 0.93269231])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b98b912f-b59e-4b4b-a23c-f438e9b7f828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45689655, 0.95344025, 0.90232558])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d21685-8361-4954-8da7-a5c36fb87cb3",
   "metadata": {},
   "source": [
    "The precision and recall scores for the hate class are far lower than the scores for the 'offensive' and 'neither' classes. This is similar to what the researchers experienced with their classifier, except that in their classifier the recall was higher than precision. With our classifier the opposite is true. For this problem recall is more important than precision. The f1 score of the hate class is similarly poor in comparison to the other classes.\n",
    "\n",
    "For reference these are the scores of Davidson et al.'s classifier on the 'hate' class compared to mine:\n",
    "\n",
    "| Metric    | Davidson Classifier | My Classifier   |\n",
    "| --------- | -------- | ---- |\n",
    "| Precision | 0.44     | 0.60 |\n",
    "| Recall    | 0.61     | 0.37 |\n",
    "| F1 Score  | 0.51     | 0.46 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce502c-ee30-4409-a090-b56cb838f9f4",
   "metadata": {},
   "source": [
    "So why are the scores on the hate class low? Well there are two reasons:\n",
    "\n",
    "First, there is not much hate speech data in this dataset. As we saw in the beginning of this notebook the hate speech class only makes up 6% of this dataset. So one possibility is that our model did not have enough data to learn what hate speech actually is. Another possibility is simply the nature of this problem. Hate speech is not a very well-defined concept, something that is considered hateful to somebody might not be to somebody else, which creates this ambiguity that does not translate well to machine learning models.\n",
    "\n",
    "So after all this work how do we know if our model is any good? If we wanted to sum it up with one metric we can look at the weighted F1 score of our model's predictions on the test set. Remember, the `weighted` averaging strategy takes into account class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "92e9eed0-d31f-4817-ab0b-359337696f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9213392496974586\n",
      "Precision:  0.9145078624930217\n",
      "Recall:  0.9213392496974586\n",
      "F1 Score:  0.9162198166715908\n"
     ]
    }
   ],
   "source": [
    "evaluate_keras_classifier(lstm_model,\n",
    "                          davidson_seq_test,\n",
    "                          y_test,\n",
    "                          averaging_strategy='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb51d1c-6a43-45b6-9772-ad0d117b9fa1",
   "metadata": {},
   "source": [
    "We end up with a pretty good score on this dataset, but of course there is always room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34381527-4783-4cea-910b-9de632fc3207",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd09eb-3c11-40b2-b7c5-2974faef36b6",
   "metadata": {},
   "source": [
    "Overall, I am quite pleased with the classifier that I built in this notebook. I wanted to also try to train a classifier on a foreign language hate speech dataset but I did not have time to do so. Classifiers like this one are being used to enforce the terms of service of a community or social media website, and there is a need to improve them, particularly for languages other than English. The techniques used in this notebook are not domain specific and can be applied to any text classification task like spam detection, article categorization, sentiment analysis, and fake news detection.\n",
    "\n",
    "I cannot imagine building a classifier like this in another language, not because of any language-specific features that python has but because of the large amount of open-source libraries available for machine learning and natural language processing. The Jupyter notebook environment made the process of building this classifier a lot easier due to the interactive nature of it. I have looked at both shallow and deep learning models, and have used different methods to represent the text data, but I have not used state of the art transformer architectures like BERT, mostly because I do not understand them well enough. These state of the art methods have received a lot of attention recently for their performance on benchmark tasks so I wouldn't be surprised if they do well on this particular dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebd60b-b58b-4814-a045-0b28ebd69d5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### References\n",
    "\n",
    "\n",
    "1. https://www.pewresearch.org/internet/2021/01/13/the-state-of-online-harassment/\n",
    "\n",
    "2. https://www.statista.com/statistics/264810/number-of-monthly-active-facebook-users-worldwide/\n",
    "\n",
    "3. https://www.forbes.com/sites/johnkoetsier/2020/06/09/300000-facebook-content-moderation-mistakes-daily-report-says/?sh=2e15774d54d0\n",
    "\n",
    "4. https://www.forbes.com/sites/traversmark/2020/03/21/facebook-spreads-fake-news-faster-than-any-other-social-website-according-to-new-research/\n",
    "\n",
    "5. https://hate-alert.github.io/\n",
    "\n",
    "6. https://apnews.com/article/technology-business-middle-east-religion-europe-a38da3ccd40ffae7e4caa450c374f796"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp-mid] *",
   "language": "python",
   "name": "conda-env-nlp-mid-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
